# Uncomment the following line to use the mocked API
#VITE_API_BASE=http://localhost:5174
#VITE_ENDPOINT_COMPLETIONS=/v1/chat/completions
#VITE_ENDPOINT_MODELS=/v1/models
#VITE_OPENAI_API_KEY="your-openai-api-key"

# Optional: configure mocked_api as a CORS-friendly reverse proxy for local dev
#MOCK_API_UPSTREAM=https://right.codes/codex

# Optional: configure Vite dev-server proxy target for /v1/* (avoids CORS without Docker)
#VITE_UPSTREAM_PROXY_TARGET=https://right.codes/codex

# ---- Public / cloudflared deployment (recommended) ----
# 1) Build the SPA: `npm run build` (creates dist/)
# 2) Run the gateway: `docker compose up -d mocked_api`
# 3) Visit: http://localhost:5174/ (then tunnel that port)
#
# Enable login protection (required for public exposure)
#APP_PASSKEY=put-a-long-random-passkey-here
#
# Optional session cookie signing secret (defaults to APP_PASSKEY)
#SESSION_SECRET=another-long-random-string
#
# Serve as a real OpenAI gateway: proxy /v1/* to UPSTREAM_BASE with a server-managed key
#MODE=proxy
#UPSTREAM_BASE=https://api.openai.com
#OPENAI_API_KEY=your-openai-api-key
#
# Build-time flags for the frontend (requires rebuild)
#VITE_SERVER_API_KEY=1
#VITE_HIDE_API_KEY_INPUT=1
# Optional: restrict the model dropdown to an allowlist (comma-separated)
#VITE_MODEL_ALLOWLIST=gpt-5,gpt-5.2

# If Docker pulls fail (Docker Hub issues), run the gateway directly:
#   npm run build
#   APP_PASSKEY=... MODE=proxy OPENAI_API_KEY=... VITE_SERVER_API_KEY=1 VITE_HIDE_API_KEY_INPUT=1 npm run gateway
